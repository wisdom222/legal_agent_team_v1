import streamlit as st
from agno.agent import Agent
from agno.run.agent import RunOutput
from agno.team import Team
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.qdrant import Qdrant
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.models.openai import OpenAIChat
from agno.knowledge.embedder.openai import OpenAIEmbedder
import tempfile
import os

# å®šä¹‰é»˜è®¤çš„ Base URLï¼Œä½œä¸ºè¾“å…¥æ¡†çš„é»˜è®¤å€¼
DEFAULT_BASE_URL = "https://api.zhizengzeng.com/v1"

def init_session_state():
    """Initialize session state variables"""
    if 'openai_api_key' not in st.session_state:
        st.session_state.openai_api_key = None
    if 'openai_base_url' not in st.session_state:
        st.session_state.openai_base_url = DEFAULT_BASE_URL
    if 'qdrant_api_key' not in st.session_state:
        st.session_state.qdrant_api_key = None
    if 'qdrant_url' not in st.session_state:
        st.session_state.qdrant_url = None
    if 'vector_db' not in st.session_state:
        st.session_state.vector_db = None
    if 'legal_team' not in st.session_state:
        st.session_state.legal_team = None
    if 'knowledge_base' not in st.session_state:
        st.session_state.knowledge_base = None
    # Add a new state variable to track processed files
    if 'processed_files' not in st.session_state:
        st.session_state.processed_files = set()

COLLECTION_NAME = "legal_documents"  # Define your collection name

def init_qdrant():
    """Initialize Qdrant client with configured settings."""
    if not all([st.session_state.qdrant_api_key, st.session_state.qdrant_url]):
        return None
    try:
        # Create Agno's Qdrant instance which implements VectorDb
        vector_db = Qdrant(
            collection=COLLECTION_NAME,
            url=st.session_state.qdrant_url,
            api_key=st.session_state.qdrant_api_key,
            embedder=OpenAIEmbedder(
                id="text-embedding-3-small", 
                api_key=st.session_state.openai_api_key,
                base_url=st.session_state.openai_base_url # ä½¿ç”¨åŠ¨æ€é…ç½®çš„ Base URL
            )
        )
        return vector_db
    except Exception as e:
        st.error(f"ğŸ”´ Qdrant è¿æ¥å¤±è´¥: {str(e)}")
        return None

def process_document(uploaded_file, vector_db: Qdrant):
    """
    Process document, create embeddings and store in Qdrant vector database
    """
    if not st.session_state.openai_api_key:
        raise ValueError("æœªæä¾› OpenAI API å¯†é’¥")
        
    os.environ['OPENAI_API_KEY'] = st.session_state.openai_api_key
    os.environ['OPENAI_BASE_URL'] = st.session_state.openai_base_url # åŒæ—¶ä¹Ÿè®¾ç½®ç¯å¢ƒå˜é‡
    
    try:
        # Save the uploaded file to a temporary location
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as temp_file:
            temp_file.write(uploaded_file.getvalue())
            temp_file_path = temp_file.name
        
        st.info("æ­£åœ¨åŠ è½½å¹¶å¤„ç†æ–‡æ¡£...")
        
        # Create a Knowledge base with the vector_db
        knowledge_base = Knowledge(
            vector_db=vector_db
        )
        
        # Add the document to the knowledge base
        with st.spinner('ğŸ“¤ æ­£åœ¨å°†æ–‡æ¡£åŠ è½½åˆ°çŸ¥è¯†åº“...'):
            try:
                knowledge_base.add_content(path=temp_file_path)
                st.success("âœ… æ–‡æ¡£å­˜å‚¨æˆåŠŸï¼")
            except Exception as e:
                st.error(f"åŠ è½½æ–‡æ¡£å‡ºé”™: {str(e)}")
                raise
        
        # Clean up the temporary file
        try:
            os.unlink(temp_file_path)
        except Exception:
            pass
            
        return knowledge_base
            
    except Exception as e:
        st.error(f"æ–‡æ¡£å¤„ç†é”™è¯¯: {str(e)}")
        raise Exception(f"å¤„ç†æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")

def main():
    st.set_page_config(page_title="æ³•å¾‹æ–‡æ¡£åˆ†æåŠ©æ‰‹", layout="wide")
    init_session_state()

    st.title("AI æ³•å¾‹æ™ºèƒ½ä½“å›¢é˜Ÿ ğŸ‘¨â€âš–ï¸")

    with st.sidebar:
        st.header("ğŸ”‘ API é…ç½®")
   
        # 1. OpenAI API Key
        openai_key = st.text_input(
            "OpenAI API Key",
            type="password",
            value=st.session_state.openai_api_key if st.session_state.openai_api_key else "",
            help="è¾“å…¥æ‚¨çš„ OpenAI API å¯†é’¥"
        )
        if openai_key:
            st.session_state.openai_api_key = openai_key

        # 2. OpenAI Base URL (æ–°å¢çš„è¾“å…¥æ¡†)
        base_url = st.text_input(
            "OpenAI Base URL",
            value=st.session_state.openai_base_url,
            help="è¾“å…¥ OpenAI ä»£ç†åœ°å€ï¼ˆå¦‚æœä½¿ç”¨å®˜æ–¹ API å¯ä¸å¡«æˆ–å¡«å®˜æ–¹åœ°å€ï¼‰"
        )
        if base_url:
            st.session_state.openai_base_url = base_url

        st.divider() # åˆ†éš”çº¿

        # 3. Qdrant API Key
        qdrant_key = st.text_input(
            "Qdrant API Key",
            type="password",
            value=st.session_state.qdrant_api_key if st.session_state.qdrant_api_key else "",
            help="è¾“å…¥æ‚¨çš„ Qdrant API å¯†é’¥"
        )
        if qdrant_key:
            st.session_state.qdrant_api_key = qdrant_key

        # 4. Qdrant URL
        qdrant_url = st.text_input(
            "Qdrant URL",
            value=st.session_state.qdrant_url if st.session_state.qdrant_url else "",
            help="è¾“å…¥æ‚¨çš„ Qdrant å®ä¾‹ URL"
        )
        if qdrant_url:
            st.session_state.qdrant_url = qdrant_url

        if all([st.session_state.qdrant_api_key, st.session_state.qdrant_url]):
            try:
                if not st.session_state.vector_db:
                    # Make sure we're initializing a QdrantClient here
                    st.session_state.vector_db = init_qdrant()
                    if st.session_state.vector_db:
                        st.success("æˆåŠŸè¿æ¥åˆ° Qdrantï¼")
            except Exception as e:
                st.error(f"è¿æ¥ Qdrant å¤±è´¥: {str(e)}")

        st.divider()

        if all([st.session_state.openai_api_key, st.session_state.vector_db]):
            st.header("ğŸ“„ æ–‡æ¡£ä¸Šä¼ ")
            uploaded_file = st.file_uploader("ä¸Šä¼ æ³•å¾‹æ–‡æ¡£", type=['pdf'])
            
            if uploaded_file:
                # Check if this file has already been processed
                if uploaded_file.name not in st.session_state.processed_files:
                    with st.spinner("æ­£åœ¨å¤„ç†æ–‡æ¡£..."):
                        try:
                            # Process the document and get the knowledge base
                            knowledge_base = process_document(uploaded_file, st.session_state.vector_db)
                            
                            if knowledge_base:
                                st.session_state.knowledge_base = knowledge_base
                                # Add the file to processed files
                                st.session_state.processed_files.add(uploaded_file.name)
                                
                                # è·å–å½“å‰çš„ Base URL
                                current_base_url = st.session_state.openai_base_url

                                # Initialize agents
                                legal_researcher = Agent(
                                    name="æ³•å¾‹ç ”ç©¶å‘˜",
                                    role="æ³•å¾‹ç ”ç©¶ä¸“å®¶",
                                    model=OpenAIChat(id="gpt-4.1",
                                                     api_key=st.session_state.openai_api_key, 
                                                     base_url=current_base_url), # ä½¿ç”¨é…ç½®çš„ Base URL
                                    tools=[DuckDuckGoTools()],
                                    knowledge=st.session_state.knowledge_base,
                                    search_knowledge=True,
                                    instructions=[
                                        "æŸ¥æ‰¾å¹¶å¼•ç”¨ç›¸å…³çš„æ³•å¾‹æ¡ˆä¾‹å’Œåˆ¤ä¾‹",
                                        "æä¾›å¸¦æœ‰æ¥æºçš„è¯¦ç»†ç ”ç©¶æ‘˜è¦",
                                        "å¼•ç”¨ä¸Šä¼ æ–‡æ¡£ä¸­çš„å…·ä½“ç« èŠ‚",
                                        "å§‹ç»ˆåœ¨çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³ä¿¡æ¯"
                                    ],
                                    debug_mode=True,
                                    markdown=True
                                )

                                contract_analyst = Agent(
                                    name="åˆåŒåˆ†æå¸ˆ",
                                    role="åˆåŒåˆ†æä¸“å®¶",
                                    model=OpenAIChat(id="gpt-4.1",
                                                     api_key=st.session_state.openai_api_key, 
                                                     base_url=current_base_url), # ä½¿ç”¨é…ç½®çš„ Base URL
                                    knowledge=st.session_state.knowledge_base,
                                    search_knowledge=True,
                                    instructions=[
                                        "å½»åº•å®¡æŸ¥åˆåŒ",
                                        "è¯†åˆ«å…³é”®æ¡æ¬¾å’Œæ½œåœ¨é—®é¢˜",
                                        "å¼•ç”¨æ–‡æ¡£ä¸­çš„å…·ä½“æ¡æ¬¾"
                                    ],
                                    markdown=True
                                )

                                legal_strategist = Agent(
                                    name="æ³•å¾‹ç­–ç•¥å¸ˆ", 
                                    role="æ³•å¾‹ç­–ç•¥ä¸“å®¶",
                                    model=OpenAIChat(id="gpt-4.1",
                                                     api_key=st.session_state.openai_api_key, 
                                                     base_url=current_base_url), # ä½¿ç”¨é…ç½®çš„ Base URL
                                    knowledge=st.session_state.knowledge_base,
                                    search_knowledge=True,
                                    instructions=[
                                        "åˆ¶å®šå…¨é¢çš„æ³•å¾‹ç­–ç•¥",
                                        "æä¾›å¯æ‰§è¡Œçš„å»ºè®®",
                                        "åŒæ—¶è€ƒè™‘é£é™©å’Œæœºé‡"
                                    ],
                                    markdown=True
                                )

                                # Legal Agent Team
                                st.session_state.legal_team = Team(
                                    name="æ³•å¾‹å›¢é˜Ÿè´Ÿè´£äºº",
                                    model=OpenAIChat(id="gpt-4.1",
                                                     api_key=st.session_state.openai_api_key, 
                                                     base_url=current_base_url), # ä½¿ç”¨é…ç½®çš„ Base URL
                                    members=[legal_researcher, contract_analyst, legal_strategist],
                                    knowledge=st.session_state.knowledge_base,
                                    search_knowledge=True,
                                    instructions=[
                                        "åè°ƒå›¢é˜Ÿæˆå‘˜ä¹‹é—´çš„åˆ†æå·¥ä½œ",
                                        "æä¾›å…¨é¢çš„å›å¤",
                                        "ç¡®ä¿æ‰€æœ‰å»ºè®®éƒ½æœ‰é€‚å½“çš„æ¥æº",
                                        "å¼•ç”¨ä¸Šä¼ æ–‡æ¡£çš„å…·ä½“éƒ¨åˆ†",
                                        "åœ¨åˆ†é…ä»»åŠ¡å‰å§‹ç»ˆå…ˆæœç´¢çŸ¥è¯†åº“"
                                    ],
                                    debug_mode=True,
                                    markdown=True
                                )
                                
                                st.success("âœ… æ–‡æ¡£å¤„ç†å®Œæˆï¼Œå›¢é˜Ÿåˆå§‹åŒ–å®Œæ¯•ï¼")
                                
                        except Exception as e:
                            st.error(f"å¤„ç†æ–‡æ¡£å‡ºé”™: {str(e)}")
                else:
                    # File already processed, just show a message
                    st.success("âœ… æ–‡æ¡£å·²å¤„ç†ï¼Œå›¢é˜Ÿå‡†å¤‡å°±ç»ªï¼")

            st.divider()
            st.header("ğŸ” åˆ†æé€‰é¡¹")
            analysis_type = st.selectbox(
                "é€‰æ‹©åˆ†æç±»å‹",
                [
                    "åˆåŒå®¡æŸ¥",
                    "æ³•å¾‹ç ”ç©¶",
                    "é£é™©è¯„ä¼°",
                    "åˆè§„æ€§æ£€æŸ¥",
                    "è‡ªå®šä¹‰æŸ¥è¯¢"
                ]
            )
        else:
            st.warning("è¯·é…ç½®æ‰€æœ‰ API å‡­è¯ä»¥ç»§ç»­")

    # Main content area
    if not all([st.session_state.openai_api_key, st.session_state.vector_db]):
        st.info("ğŸ‘ˆ è¯·åœ¨ä¾§è¾¹æ é…ç½®æ‚¨çš„ API å‡­è¯ä»¥å¼€å§‹")
    elif not uploaded_file:
        st.info("ğŸ‘ˆ è¯·ä¸Šä¼ æ³•å¾‹æ–‡æ¡£ä»¥å¼€å§‹åˆ†æ")
    elif st.session_state.legal_team:
        # Create a dictionary for analysis type icons
        analysis_icons = {
            "åˆåŒå®¡æŸ¥": "ğŸ“‘",
            "æ³•å¾‹ç ”ç©¶": "ğŸ”",
            "é£é™©è¯„ä¼°": "âš ï¸",
            "åˆè§„æ€§æ£€æŸ¥": "âœ…",
            "è‡ªå®šä¹‰æŸ¥è¯¢": "ğŸ’­"
        }

        # Dynamic header with icon
        st.header(f"{analysis_icons[analysis_type]} {analysis_type}")
  
        analysis_configs = {
            "åˆåŒå®¡æŸ¥": {
                "query": "å®¡æŸ¥æ­¤åˆåŒå¹¶è¯†åˆ«å…³é”®æ¡æ¬¾ã€ä¹‰åŠ¡å’Œæ½œåœ¨é—®é¢˜ã€‚",
                "agents": ["åˆåŒåˆ†æå¸ˆ"],
                "description": "ä¸“æ³¨äºæ¡æ¬¾å’Œä¹‰åŠ¡çš„è¯¦ç»†åˆåŒåˆ†æ"
            },
            "æ³•å¾‹ç ”ç©¶": {
                "query": "ç ”ç©¶ä¸æ­¤æ–‡æ¡£ç›¸å…³çš„æ¡ˆä¾‹å’Œåˆ¤ä¾‹ã€‚",
                "agents": ["æ³•å¾‹ç ”ç©¶å‘˜"],
                "description": "ç›¸å…³æ³•å¾‹æ¡ˆä¾‹å’Œåˆ¤ä¾‹çš„ç ”ç©¶"
            },
            "é£é™©è¯„ä¼°": {
                "query": "åˆ†ææ­¤æ–‡æ¡£ä¸­çš„æ½œåœ¨æ³•å¾‹é£é™©å’Œè´£ä»»ã€‚",
                "agents": ["åˆåŒåˆ†æå¸ˆ", "æ³•å¾‹ç­–ç•¥å¸ˆ"],
                "description": "ç»¼åˆé£é™©åˆ†æå’Œæˆ˜ç•¥è¯„ä¼°"
            },
            "åˆè§„æ€§æ£€æŸ¥": {
                "query": "æ£€æŸ¥æ­¤æ–‡æ¡£çš„ç›‘ç®¡åˆè§„æ€§é—®é¢˜ã€‚",
                "agents": ["æ³•å¾‹ç ”ç©¶å‘˜", "åˆåŒåˆ†æå¸ˆ", "æ³•å¾‹ç­–ç•¥å¸ˆ"],
                "description": "å…¨é¢çš„åˆè§„æ€§åˆ†æ"
            },
            "è‡ªå®šä¹‰æŸ¥è¯¢": {
                "query": None,
                "agents": ["æ³•å¾‹ç ”ç©¶å‘˜", "åˆåŒåˆ†æå¸ˆ", "æ³•å¾‹ç­–ç•¥å¸ˆ"],
                "description": "ä½¿ç”¨æ‰€æœ‰å¯ç”¨æ™ºèƒ½ä½“çš„è‡ªå®šä¹‰åˆ†æ"
            }
        }

        st.info(f"ğŸ“‹ {analysis_configs[analysis_type]['description']}")
        st.write(f"ğŸ¤– æ´»è·ƒæ³•å¾‹ AI æ™ºèƒ½ä½“: {', '.join(analysis_configs[analysis_type]['agents'])}")  #dictionary!!

        # Replace the existing user_query section with this:
        if analysis_type == "è‡ªå®šä¹‰æŸ¥è¯¢":
            user_query = st.text_area(
                "è¾“å…¥æ‚¨çš„å…·ä½“é—®é¢˜:",
                help="æ·»åŠ æ‚¨æƒ³åˆ†æçš„ä»»ä½•å…·ä½“é—®é¢˜æˆ–è¦ç‚¹"
            )
        else:
            user_query = None  # Set to None for non-custom queries


        if st.button("å¼€å§‹åˆ†æ"):
            if analysis_type == "è‡ªå®šä¹‰æŸ¥è¯¢" and not user_query:
                st.warning("è¯·è¾“å…¥é—®é¢˜")
            else:
                with st.spinner("æ­£åœ¨åˆ†ææ–‡æ¡£..."):
                    try:
                        # Ensure OpenAI API key is set
                        os.environ['OPENAI_API_KEY'] = st.session_state.openai_api_key
                        os.environ['OPENAI_BASE_URL'] = st.session_state.openai_base_url # ç¡®ä¿ç¯å¢ƒå˜é‡ä¹Ÿæ›´æ–°
                        
                        # Combine predefined and user queries
                        if analysis_type != "è‡ªå®šä¹‰æŸ¥è¯¢":
                            combined_query = f"""
                            ä½¿ç”¨ä¸Šä¼ çš„æ–‡æ¡£ä½œä¸ºå‚è€ƒï¼š
                            
                            ä¸»è¦åˆ†æä»»åŠ¡ï¼š{analysis_configs[analysis_type]['query']}
                            å…³æ³¨é¢†åŸŸï¼š{', '.join(analysis_configs[analysis_type]['agents'])}
                            
                            è¯·æœç´¢çŸ¥è¯†åº“å¹¶æä¾›æ–‡æ¡£ä¸­çš„å…·ä½“å¼•ç”¨ã€‚
                            """
                        else:
                            combined_query = f"""
                            ä½¿ç”¨ä¸Šä¼ çš„æ–‡æ¡£ä½œä¸ºå‚è€ƒï¼š
                            
                            {user_query}
                            
                            è¯·æœç´¢çŸ¥è¯†åº“å¹¶æä¾›æ–‡æ¡£ä¸­çš„å…·ä½“å¼•ç”¨ã€‚
                            å…³æ³¨é¢†åŸŸï¼š{', '.join(analysis_configs[analysis_type]['agents'])}
                            """

                        response: RunOutput = st.session_state.legal_team.run(combined_query)
                        
                        # Display results in tabs
                        tabs = st.tabs(["åˆ†æç»“æœ", "å…³é”®ç‚¹", "å»ºè®®"])
                        
                        with tabs[0]:
                            st.markdown("### è¯¦ç»†åˆ†æ")
                            if response.content:
                                st.markdown(response.content)
                            else:
                                for message in response.messages:
                                    if message.role == 'assistant' and message.content:
                                        st.markdown(message.content)
                        
                        with tabs[1]:
                            st.markdown("### å…³é”®ç‚¹")
                            key_points_response: RunOutput = st.session_state.legal_team.run(
                                f"""åŸºäºä¹‹å‰çš„åˆ†æï¼š    
                                {response.content}
                                
                                è¯·ç”¨è¦ç‚¹å½¢å¼æ€»ç»“å…³é”®ç‚¹ã€‚
                                é‡ç‚¹å…³æ³¨æ¥è‡ªä»¥ä¸‹æ–¹é¢çš„è§è§£ï¼š{', '.join(analysis_configs[analysis_type]['agents'])}"""
                            )
                            if key_points_response.content:
                                st.markdown(key_points_response.content)
                            else:
                                for message in key_points_response.messages:
                                    if message.role == 'assistant' and message.content:
                                        st.markdown(message.content)
                        
                        with tabs[2]:
                            st.markdown("### å»ºè®®")
                            recommendations_response: RunOutput = st.session_state.legal_team.run(
                                f"""åŸºäºä¹‹å‰çš„åˆ†æï¼š
                                {response.content}
                                
                                åŸºäºåˆ†æï¼Œæ‚¨çš„å…³é”®å»ºè®®æ˜¯ä»€ä¹ˆï¼Œæœ€ä½³è¡ŒåŠ¨æ–¹æ¡ˆæ˜¯ä»€ä¹ˆï¼Ÿ
                                æä¾›æ¥è‡ªä»¥ä¸‹æ–¹é¢çš„å…·ä½“å»ºè®®ï¼š{', '.join(analysis_configs[analysis_type]['agents'])}"""
                            )
                            if recommendations_response.content:
                                st.markdown(recommendations_response.content)
                            else:
                                for message in recommendations_response.messages:
                                    if message.role == 'assistant' and message.content:
                                        st.markdown(message.content)

                    except Exception as e:
                        st.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
    else:
        st.info("è¯·ä¸Šä¼ æ³•å¾‹æ–‡æ¡£ä»¥å¼€å§‹åˆ†æ")

if __name__ == "__main__":
    main()